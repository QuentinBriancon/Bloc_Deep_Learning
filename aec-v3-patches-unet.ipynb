{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f183736",
   "metadata": {},
   "source": [
    "## 1. Chargement des Bibliothèques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcea2652",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, callbacks\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import keras.backend as K\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "# Reproductibilité\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83270c09",
   "metadata": {},
   "source": [
    "## 2. Paramètres et Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b043a04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (32, 32) \n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 100\n",
    "VAL_SPLIT = 0.2\n",
    "TEST_SPLIT = 0.1\n",
    "DATA_PATH = 'Data Science/Datasets/Dataset Livrable 2 - patches/patches/processed/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72c5aea",
   "metadata": {},
   "source": [
    "## 3. Chargement et Préparation des Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185e154b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path):\n",
    "    # Vérification hiérarchique renforcée\n",
    "    noisy_path = os.path.join(data_path, 'noisy')\n",
    "    clean_path = os.path.join(data_path, 'clean')\n",
    "    \n",
    "    for path in [noisy_path, clean_path]:\n",
    "        if not os.path.isdir(path):\n",
    "            raise ValueError(f\"Dossier introuvable: {path}\")\n",
    "    \n",
    "    # Collecte avec vérification d'extension\n",
    "    valid_ext = ['.jpg', '.jpeg', '.png']\n",
    "    \n",
    "    noisy_files = sorted([f for f in os.listdir(noisy_path) \n",
    "                         if os.path.splitext(f)[1].lower() in valid_ext])\n",
    "    clean_files = sorted([f for f in os.listdir(clean_path)\n",
    "                         if os.path.splitext(f)[1].lower() in valid_ext])\n",
    "\n",
    "    # Lecture avec progression et gestion d'erreur\n",
    "    noisy_imgs, clean_imgs = [], []\n",
    "    for idx, (nfile, cfile) in enumerate(zip(noisy_files, clean_files)):\n",
    "        noisy_img = cv2.imread(os.path.join(noisy_path, nfile))\n",
    "        noisy_img = cv2.cvtColor(noisy_img, cv2.COLOR_BGR2RGB)\n",
    "        clean_img = cv2.imread(os.path.join(clean_path, cfile))\n",
    "        clean_img = cv2.cvtColor(clean_img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if noisy_img is None:\n",
    "            print(f\"ERREUR: Échec de lecture de {nfile} (taille attendue: {IMG_SIZE})\")\n",
    "            continue\n",
    "        if clean_img is None:\n",
    "            print(f\"ERREUR: Échec de lecture de {cfile} (taille attendue: {IMG_SIZE})\")\n",
    "            continue\n",
    "        \n",
    "        # Vérification de la taille\n",
    "        if noisy_img.shape != (*IMG_SIZE, 3):\n",
    "            print(f\"Avertissement: {nfile} a une taille {noisy_img.shape}, ignoré\")\n",
    "            continue\n",
    "            \n",
    "        noisy_imgs.append(noisy_img)\n",
    "        clean_imgs.append(clean_img)\n",
    "        \n",
    "        if (idx+1) % 10 == 0:\n",
    "            print(f\"Traité {idx+1}/{len(noisy_files)} paires\")\n",
    "\n",
    "    print(f\"\\nSuccès: {len(noisy_imgs)} paires valides sur {len(noisy_files)}\")\n",
    "    return np.array(noisy_imgs), np.array(clean_imgs)\n",
    "\n",
    "# Chargement avec vérification\n",
    "try:\n",
    "    X_noisy, X_clean = load_data(DATA_PATH)\n",
    "except Exception as e:\n",
    "    print(f\"Erreur: {e}\")\n",
    "    raise\n",
    "\n",
    "# Vérification des dimensions\n",
    "assert X_noisy.shape == X_clean.shape, \"Dimensions incohérentes entre X_noisy et X_clean!\"\n",
    "\n",
    "# Normalisation [0,1]\n",
    "X_noisy = X_noisy.astype('float32') / 255.0\n",
    "X_clean = X_clean.astype('float32') / 255.0\n",
    "\n",
    "# Split adaptatif pour petits datasets\n",
    "TOTAL_SIZE = len(X_noisy)\n",
    "print(f\"Total d'images: {TOTAL_SIZE}\")\n",
    "if TOTAL_SIZE < 100:\n",
    "    # Stratégie pour datasets réduits\n",
    "    TEST_SPLIT = max(1, int(0.1 * TOTAL_SIZE))\n",
    "    VAL_SPLIT = max(1, int(0.2 * TOTAL_SIZE))\n",
    "else:\n",
    "    TEST_SPLIT = 0.1\n",
    "    VAL_SPLIT = 0.2\n",
    "\n",
    "# Split avec shuffle stratifié\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X_noisy, X_clean, \n",
    "    test_size=(VAL_SPLIT + TEST_SPLIT), \n",
    "    random_state=SEED,\n",
    "    shuffle=True\n",
    ")\n",
    "# Creation of validation and test sets\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp,\n",
    "    test_size=TEST_SPLIT/(VAL_SPLIT + TEST_SPLIT), \n",
    "    random_state=SEED\n",
    ")\n",
    "\n",
    "print(f\"\\nSplit Final:\")\n",
    "print(f\"- Train: {len(X_train)}\")\n",
    "print(f\"- Val: {len(X_val)}\")\n",
    "print(f\"- Test: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba485bff",
   "metadata": {},
   "source": [
    "## 4. Définition du Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bcf7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, callbacks\n",
    "import numpy as np\n",
    "\n",
    "# --- Residual Block ---\n",
    "def ResidualConvBlock(x, filters):\n",
    "    shortcut = x\n",
    "    x = layers.Conv2D(filters, 3, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv2D(filters, 3, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    # Adapter le shortcut si le nombre de canaux ne correspond pas\n",
    "    if shortcut.shape[-1] != filters:\n",
    "        shortcut = layers.Conv2D(filters, 1, padding='same')(shortcut)\n",
    "    x = layers.Add()([shortcut, x])\n",
    "    x = layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "# --- Attention Block ---\n",
    "class SpatialAttention(layers.Layer):\n",
    "    def __init__(self, ratio=8, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.ratio = ratio\n",
    "\n",
    "    # Override build method to create layers\n",
    "    def build(self, input_shape):\n",
    "        channels = input_shape[-1]\n",
    "        self.dense1 = layers.Dense(channels // self.ratio, activation='relu', use_bias=False)\n",
    "        self.dense2 = layers.Dense(channels, activation='sigmoid', use_bias=False)\n",
    "        self.conv = layers.Conv2D(1, 7, padding='same', activation='sigmoid')\n",
    "        super().build(input_shape)\n",
    "\n",
    "    # Override call method to define forward pass\n",
    "    def call(self, x):\n",
    "        channels = x.shape[-1]\n",
    "        avg_pool = layers.GlobalAveragePooling2D()(x)\n",
    "        avg_pool = layers.Reshape((1, 1, channels))(avg_pool)\n",
    "        avg_pool = self.dense1(avg_pool)\n",
    "        avg_pool = self.dense2(avg_pool)\n",
    "        max_pool = tf.reduce_max(x, axis=-1, keepdims=True)\n",
    "        avg_pool_spatial = tf.reduce_mean(x, axis=-1, keepdims=True)\n",
    "        concat = tf.concat([max_pool, avg_pool_spatial], axis=-1)\n",
    "        spatial = self.conv(concat)\n",
    "        return x * avg_pool * spatial\n",
    "\n",
    "# --- U-Net with Residuals and Attention ---\n",
    "def build_denoising_unet(input_shape=(32,32,3)):\n",
    "    inputs = layers.Input(input_shape)\n",
    "    # Encoder\n",
    "    e1 = layers.Conv2D(64, 3, padding='same', activation='relu')(inputs)\n",
    "    e1 = ResidualConvBlock(e1, 64)\n",
    "    p1 = layers.MaxPooling2D()(e1)\n",
    "    e2 = layers.Conv2D(128, 3, padding='same', activation='relu')(p1)\n",
    "    e2 = ResidualConvBlock(e2, 128)\n",
    "    p2 = layers.MaxPooling2D()(e2)\n",
    "    # Bottleneck\n",
    "    b = layers.Conv2D(256, 3, padding='same', activation='relu')(p2)\n",
    "    b = ResidualConvBlock(b, 256)\n",
    "    b = SpatialAttention()(b)\n",
    "    b = layers.Dropout(0.3)(b)\n",
    "    # Decoder\n",
    "    d1 = layers.Conv2DTranspose(128, 3, strides=2, padding='same', activation='relu')(b)\n",
    "    d1 = layers.Concatenate()([d1, e2])\n",
    "    d1 = ResidualConvBlock(d1, 128)\n",
    "    d2 = layers.Conv2DTranspose(64, 3, strides=2, padding='same', activation='relu')(d1)\n",
    "    d2 = layers.Concatenate()([d2, e1])\n",
    "    d2 = ResidualConvBlock(d2, 64)\n",
    "    outputs = layers.Conv2D(3, 1, activation='sigmoid')(d2)\n",
    "    return Model(inputs, outputs)\n",
    "\n",
    "# --- Hybrid Loss (MSE + SSIM + Perceptual) ---\n",
    "vgg = tf.keras.applications.VGG16(include_top=False, weights='imagenet', input_shape=(32,32,3))\n",
    "loss_model = Model(inputs=vgg.input, outputs=vgg.get_layer('block3_conv3').output)\n",
    "loss_model.trainable = False\n",
    "\n",
    "# --- Custom Loss Function ---\n",
    "def hybrid_loss(y_true, y_pred):\n",
    "    ssim_loss = 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, 1.0))\n",
    "    mse_loss = tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "    y_true_features = loss_model(y_true)\n",
    "    y_pred_features = loss_model(y_pred)\n",
    "    perceptual_loss = tf.reduce_mean(tf.square(y_true_features - y_pred_features))\n",
    "    return 0.5*ssim_loss + 0.4*mse_loss + 0.1*perceptual_loss\n",
    "\n",
    "# --- Metrics ---\n",
    "def PSNR(y_true, y_pred):\n",
    "    return tf.image.psnr(y_true, y_pred, max_val=1.0)\n",
    "def SSIM(y_true, y_pred):\n",
    "    return tf.image.ssim(y_true, y_pred, max_val=1.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08395b62",
   "metadata": {},
   "source": [
    "## 5. Compilation du Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3addf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model Compile ---\n",
    "model = build_denoising_unet(input_shape=(32,32,3))\n",
    "model.compile(optimizer='adam', loss=hybrid_loss, metrics=[PSNR, SSIM])\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efd4da9",
   "metadata": {},
   "source": [
    "## 6. Entraînement du Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5439540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajoute ce callback pour réduire le learning rate si la val_loss stagne\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=8, min_lr=1e-6, verbose=1)\n",
    "\n",
    "# Modifie l’EarlyStopping\n",
    "early_stop = callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "# Ajoute du data augmentation simple (optionnel)\n",
    "data_gen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    rotation_range=20,\n",
    "    brightness_range=[0.8,1.2]\n",
    ")\n",
    "\n",
    "# Entraînement du modèle avec validation et callbacks\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=16,\n",
    "    callbacks=[early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f723369",
   "metadata": {},
   "source": [
    "## 7. Sauvegarde du Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb641f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde du modèle\n",
    "model.save('Data Science/deepvision-main/deepvision-main/notebooks/livrable2/denoising_unet_model.h5')\n",
    "print(\"✅ Modèle sauvegardé sous 'denoising_unet_model.h5'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251b244c",
   "metadata": {},
   "source": [
    "## 8. Chargement du Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c645714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du modèle\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Définir les objets personnalisés pour le chargement du modèle\n",
    "custom_objects = {\n",
    "    'hybrid_loss': hybrid_loss,\n",
    "    'PSNR': PSNR,\n",
    "    'SSIM': SSIM,\n",
    "    'SpatialAttention': SpatialAttention  # Ajout de la couche personnalisée\n",
    "}\n",
    "\n",
    "# Charger le modèle sauvegardé\n",
    "model = load_model('Data Science/deepvision-main/deepvision-main/notebooks/livrable2/denoising_unet_model.h5', custom_objects=custom_objects)\n",
    "print(\"✅ Modèle chargé depuis 'denoising_unet_model.h5'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6045eaa0",
   "metadata": {},
   "source": [
    "## 9. Évaluation du Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26774ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Test ---\n",
    "test_results = model.evaluate(X_test, y_test, batch_size=16)\n",
    "print(f\"Test Loss: {test_results[0]:.4f}, PSNR: {test_results[1]:.2f}, SSIM: {test_results[2]:.4f}\")\n",
    "\n",
    "# --- Visualisation sur quelques patches ---\n",
    "import matplotlib.pyplot as plt\n",
    "idx = np.random.choice(len(X_test), 5, replace=False)\n",
    "for i in idx:\n",
    "    noisy = X_test[i]\n",
    "    clean = y_test[i]\n",
    "    denoised = model.predict(np.expand_dims(noisy, 0))[0]\n",
    "    plt.figure(figsize=(9,3))\n",
    "    plt.subplot(1,3,1); plt.imshow(noisy); plt.title(\"Noisy\"); plt.axis('off')\n",
    "    plt.subplot(1,3,2); plt.imshow(denoised); plt.title(\"Denoised\"); plt.axis('off')\n",
    "    plt.subplot(1,3,3); plt.imshow(clean); plt.title(\"Clean\"); plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c659fcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Fonction pour reconstruire une image à partir de patches\n",
    "def reconstruct_from_patches(patches, positions, image_shape, patch_size=32):\n",
    "    \"\"\"\n",
    "    Reconstruit une image à partir de ses patches et positions.\n",
    "    \"\"\"\n",
    "    h, w, c = image_shape\n",
    "    recon = np.zeros((h, w, c), dtype=np.float32)\n",
    "    weight = np.zeros((h, w, c), dtype=np.float32)\n",
    "    for patch, (y, x) in zip(patches, positions):\n",
    "        recon[y:y+patch_size, x:x+patch_size] += patch\n",
    "        weight[y:y+patch_size, x:x+patch_size] += 1\n",
    "    weight[weight == 0] = 1\n",
    "    return recon / weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11a2a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour extraire des patches d'une image\n",
    "def extract_patches_and_positions(image, patch_size=32, stride=32):\n",
    "    \"\"\"\n",
    "    Découpe une image en patches et retourne aussi les positions (y, x).\n",
    "    \"\"\"\n",
    "    h, w, c = image.shape\n",
    "    patches = []\n",
    "    positions = []\n",
    "    for y in range(0, h - patch_size + 1, stride):\n",
    "        for x in range(0, w - patch_size + 1, stride):\n",
    "            patch = image[y:y+patch_size, x:x+patch_size, :]\n",
    "            patches.append(patch)\n",
    "            positions.append((y, x))\n",
    "    return np.array(patches), positions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ff06a7",
   "metadata": {},
   "source": [
    "## 10. Denoising et Reconstruction de 10 Patches Aléatoires\n",
    "\n",
    "Dans cette section, nous sélectionnons une image bruitée et la découpons en plusieurs patches. Nous utilisons le modèle pour débruiter ces patches, puis nous reconstruisons l'image progressivement en affichant 10 patches aléatoires.\n",
    "\n",
    "### Étapes :\n",
    "1. Charger une image bruitée et propre correspondante.\n",
    "2. Découper l'image bruitée en patches de taille fixe.\n",
    "3. Débruiter les patches avec le modèle.\n",
    "4. Reconstruire l'image progressivement en affichant 10 patches aléatoires et leur contribution à la reconstruction.\n",
    "5. Comparer visuellement l'image reconstruite avec l'image propre de référence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279a62e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "def eval_denoising_on_first_image(model, noisy_dir, clean_dir, patch_size=32, stride=16):\n",
    "\n",
    "    # Charger seulement la première image\n",
    "    noisy_files = sorted([f for f in os.listdir(noisy_dir) if f.lower().endswith(('.jpg', '.png'))])\n",
    "    clean_files = sorted([f for f in os.listdir(clean_dir) if f.lower().endswith(('.jpg', '.png'))])\n",
    "    \n",
    "    if not noisy_files or not clean_files:\n",
    "        print(\"Aucune image trouvée dans les répertoires.\")\n",
    "        return\n",
    "\n",
    "    # Lire la première image\n",
    "    nfile = noisy_files[0]\n",
    "    cfile = clean_files[0]\n",
    "\n",
    "    noisy_img = cv2.imread(os.path.join(noisy_dir, nfile))\n",
    "    noisy_img = cv2.cvtColor(noisy_img, cv2.COLOR_BGR2RGB)\n",
    "    clean_img = cv2.imread(os.path.join(clean_dir, cfile))\n",
    "    clean_img = cv2.cvtColor(clean_img, cv2.COLOR_BGR2RGB)\n",
    "    h, w, c = noisy_img.shape\n",
    "\n",
    "    # Padding pour couverture totale\n",
    "    pad_h = (np.ceil(h / patch_size) * patch_size).astype(int) - h\n",
    "    pad_w = (np.ceil(w / patch_size) * patch_size).astype(int) - w\n",
    "    noisy_pad = cv2.copyMakeBorder(noisy_img, 0, pad_h, 0, pad_w, cv2.BORDER_REFLECT)\n",
    "    clean_pad = cv2.copyMakeBorder(clean_img, 0, pad_h, 0, pad_w, cv2.BORDER_REFLECT)\n",
    "\n",
    "    noisy_norm = noisy_pad.astype(np.float32) / 255.0\n",
    "    clean_norm = clean_pad.astype(np.float32) / 255.0\n",
    "\n",
    "    # Découper l’image en patches\n",
    "    patches = []\n",
    "    positions = []\n",
    "    for y in range(0, noisy_pad.shape[0] - patch_size + 1, stride):\n",
    "        for x in range(0, noisy_pad.shape[1] - patch_size + 1, stride):\n",
    "            patch = noisy_norm[y:y+patch_size, x:x+patch_size, :]\n",
    "            patches.append(patch)\n",
    "            positions.append((y, x))\n",
    "    patches = np.array(patches)\n",
    "\n",
    "    # Prédire avec le modèle\n",
    "    denoised_patches = model.predict(patches, verbose=0)\n",
    "\n",
    "    # Visualiser la reconstruction progressive avec 10 patches aléatoires\n",
    "    sample_indices = random.sample(range(len(positions)), 10)\n",
    "    recon_step = np.zeros_like(noisy_pad, dtype=np.float32)\n",
    "    weight_step = np.zeros_like(noisy_pad, dtype=np.float32)\n",
    "\n",
    "    for i, idx in enumerate(sample_indices):\n",
    "        y, x = positions[idx]\n",
    "        patch = denoised_patches[idx]\n",
    "        recon_step[y:y+patch_size, x:x+patch_size] += patch\n",
    "        weight_step[y:y+patch_size, x:x+patch_size] += 1\n",
    "        recon_vis = recon_step / np.maximum(weight_step, 1e-8)\n",
    "\n",
    "        # Affichage\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow((patch * 255).astype(np.uint8))\n",
    "        plt.title(f\"Patch {i+1} ajouté\\nPosition: ({y}, {x})\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow((recon_vis * 255).astype(np.uint8))\n",
    "        plt.title(\"Reconstruction\\nPartielle\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(clean_pad)\n",
    "        plt.title(\"Image Clean (référence)\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.suptitle(f\"Étape {i+1} sur 10\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Exemple d'utilisation :\n",
    "noisy_dir = \"Data Science/Datasets/Dataset Livrable 2 - patches/processed/noisy\"\n",
    "clean_dir = \"Data Science/Datasets/Dataset Livrable 2 - patches/processed/clean\"\n",
    "eval_denoising_on_first_image(model, noisy_dir, clean_dir, patch_size=32, stride=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da618a0",
   "metadata": {},
   "source": [
    "## 11. Denoising de 10 Images\n",
    "\n",
    "Nous évaluons les performances du modèle sur 10 images bruitées. Pour chaque image :\n",
    "- Nous affichons l'image bruitée, l'image débruitée par le modèle et l'image propre de référence.\n",
    "- Nous calculons les métriques PSNR (Peak Signal-to-Noise Ratio) et SSIM (Structural Similarity Index Measure) pour évaluer la qualité de la débruitage.\n",
    "\n",
    "### Étapes :\n",
    "1. Charger 10 images bruitées et propres correspondantes.\n",
    "2. Débruiter chaque image avec le modèle.\n",
    "3. Afficher les résultats pour chaque image :\n",
    "   - Image bruitée.\n",
    "   - Image débruitée.\n",
    "   - Image propre (référence).\n",
    "4. Calculer et afficher les métriques PSNR et SSIM pour chaque image.\n",
    "5. Résumer les performances moyennes sur les 10 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2052936",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr, structural_similarity as ssim\n",
    "\n",
    "\n",
    "# Fonction pour évaluer le modèle sur un dossier d'images\n",
    "def eval_denoising_on_folder(model, noisy_dir, clean_dir, patch_size=32, stride=16, max_images=10):\n",
    "    noisy_files = sorted([f for f in os.listdir(noisy_dir) if f.lower().endswith(('.jpg', '.png'))])\n",
    "    clean_files = sorted([f for f in os.listdir(clean_dir) if f.lower().endswith(('.jpg', '.png'))])\n",
    "    noisy_files = noisy_files[:max_images]\n",
    "    clean_files = clean_files[:max_images]\n",
    "    psnr_list, ssim_list = [], []\n",
    "\n",
    "    # Boucle sur les fichiers pour comparer les images noisy et clean\n",
    "    for nfile, cfile in zip(noisy_files, clean_files):\n",
    "        noisy_img = cv2.imread(os.path.join(noisy_dir, nfile))\n",
    "        noisy_img = cv2.cvtColor(noisy_img, cv2.COLOR_BGR2RGB)\n",
    "        clean_img = cv2.imread(os.path.join(clean_dir, cfile))\n",
    "        clean_img = cv2.cvtColor(clean_img, cv2.COLOR_BGR2RGB)\n",
    "        h, w, c = noisy_img.shape\n",
    "\n",
    "        # Padding pour couvrir toute l'image\n",
    "        pad_h = (np.ceil(h / patch_size) * patch_size).astype(int) - h\n",
    "        pad_w = (np.ceil(w / patch_size) * patch_size).astype(int) - w\n",
    "        noisy_pad = cv2.copyMakeBorder(noisy_img, 0, pad_h, 0, pad_w, cv2.BORDER_REFLECT)\n",
    "        clean_pad = cv2.copyMakeBorder(clean_img, 0, pad_h, 0, pad_w, cv2.BORDER_REFLECT)\n",
    "        noisy_norm = noisy_pad.astype(np.float32) / 255.0\n",
    "        clean_norm = clean_pad.astype(np.float32) / 255.0\n",
    "\n",
    "        # Découpage en patches avec overlap\n",
    "        patches = []\n",
    "        positions = []\n",
    "        for y in range(0, noisy_pad.shape[0] - patch_size + 1, stride):\n",
    "            for x in range(0, noisy_pad.shape[1] - patch_size + 1, stride):\n",
    "                patch = noisy_norm[y:y+patch_size, x:x+patch_size, :]\n",
    "                patches.append(patch)\n",
    "                positions.append((y, x))\n",
    "        patches = np.array(patches)\n",
    "\n",
    "        # Prédiction des patches\n",
    "        denoised_patches = model.predict(patches, verbose=0)\n",
    "\n",
    "        # Reconstruction de l'image à partir des patches\n",
    "        recon = np.zeros_like(noisy_pad, dtype=np.float32)\n",
    "        weight = np.zeros_like(noisy_pad, dtype=np.float32)\n",
    "        idx = 0\n",
    "        for y, x in positions:\n",
    "            recon[y:y+patch_size, x:x+patch_size] += denoised_patches[idx]\n",
    "            weight[y:y+patch_size, x:x+patch_size] += 1\n",
    "            idx += 1\n",
    "        recon = recon / np.maximum(weight, 1e-8)\n",
    "        recon = recon[:h, :w]\n",
    "        clean_crop = clean_norm[:h, :w]\n",
    "\n",
    "        # Calcul métriques\n",
    "        psnr_val = psnr(clean_crop, recon, data_range=1.0)\n",
    "        ssim_val = ssim(clean_crop, recon, channel_axis=-1, data_range=1.0)\n",
    "        psnr_list.append(psnr_val)\n",
    "        ssim_list.append(ssim_val)\n",
    "\n",
    "        # Affichage\n",
    "        plt.figure(figsize=(12,4))\n",
    "        plt.subplot(1,3,1); plt.imshow(noisy_img); plt.title(\"Noisy\"); plt.axis('off')\n",
    "        plt.subplot(1,3,2); plt.imshow((recon*255).astype(np.uint8)); plt.title(f\"Denoised\\nPSNR={psnr_val:.2f} SSIM={ssim_val:.3f}\"); plt.axis('off')\n",
    "        plt.subplot(1,3,3); plt.imshow(clean_img); plt.title(\"Clean\"); plt.axis('off')\n",
    "        plt.suptitle(nfile)\n",
    "        plt.show()\n",
    "\n",
    "    print(f\"Average PSNR: {np.mean(psnr_list):.2f} dB\")\n",
    "    print(f\"Average SSIM: {np.mean(ssim_list):.3f}\")\n",
    "\n",
    "# Utilisation :\n",
    "noisy_dir = \"Data Science/Datasets/Dataset Livrable 2 - patches/processed/noisy\"\n",
    "clean_dir = \"Data Science/Datasets/Dataset Livrable 2 - patches/processed/clean\"\n",
    "\n",
    "eval_denoising_on_folder(model, noisy_dir, clean_dir, patch_size=32, stride=2, max_images=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e9316b",
   "metadata": {},
   "source": [
    "## 12. Denoising de 2 Images avec Différents Niveaux de Bruit\n",
    "\n",
    "Dans cette section, nous testons la robustesse du modèle en ajoutant différents niveaux de bruit (\"salt & pepper\") à deux images propres. Nous évaluons la capacité du modèle à débruiter ces images.\n",
    "\n",
    "### Étapes :\n",
    "1. Sélectionner deux images propres.\n",
    "2. Ajouter des niveaux croissants de bruit \"salt & pepper\" (par exemple, 0%, 10%, 20%, ..., 100%).\n",
    "3. Débruiter les images bruitées avec le modèle.\n",
    "4. Afficher les résultats pour chaque niveau de bruit :\n",
    "   - Image bruitée.\n",
    "   - Image débruitée.\n",
    "   - Image propre (référence).\n",
    "5. Calculer les métriques PSNR et SSIM pour chaque niveau de bruit.\n",
    "6. Résumer les performances sous forme de graphiques :\n",
    "   - PSNR moyen en fonction du niveau de bruit.\n",
    "   - SSIM moyen en fonction du niveau de bruit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4fb6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr, structural_similarity as ssim\n",
    "\n",
    "# Fonction pour ajouter du bruit salt & pepper à une image normalisée [0,1]\n",
    "def add_salt_pepper_noise(image, noise_level):\n",
    "    \"\"\"\n",
    "    Ajoute du bruit salt & pepper à une image normalisée [0,1].\n",
    "    noise_level: proportion de pixels bruités (ex: 0.1 = 10%)\n",
    "    \"\"\"\n",
    "    noisy = image.copy()\n",
    "    h, w, c = noisy.shape\n",
    "    num_pixels = int(noise_level * h * w)\n",
    "    # Salt\n",
    "    coords = [np.random.randint(0, i - 1, num_pixels) for i in (h, w)]\n",
    "    noisy[coords[0], coords[1], :] = 1\n",
    "    # Pepper\n",
    "    coords = [np.random.randint(0, i - 1, num_pixels) for i in (h, w)]\n",
    "    noisy[coords[0], coords[1], :] = 0\n",
    "    return noisy\n",
    "\n",
    "\n",
    "\n",
    "# Paramètres\n",
    "noise_levels = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 1.0]\n",
    "large_noisy_dir = \"Data Science/Datasets/Dataset Livrable 2 - patches/processed/noisy\"\n",
    "large_clean_dir = \"Data Science/Datasets/Dataset Livrable 2 - patches/processed/clean\"\n",
    "large_files = sorted([f for f in os.listdir(large_clean_dir) if f.lower().endswith(('.jpg', '.png'))])[:2]  # Moins d'images pour mieux voir\n",
    "\n",
    "metrics = {level: {'psnr': [], 'ssim': []} for level in noise_levels}\n",
    "\n",
    "# Boucle sur les fichiers pour comparer les images noisy et clean\n",
    "for idx, fname in enumerate(large_files):\n",
    "    clean_img = cv2.imread(os.path.join(large_clean_dir, fname))\n",
    "    clean_img = cv2.cvtColor(clean_img, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0\n",
    "    h, w, c = clean_img.shape\n",
    "\n",
    "    # On affiche une image par ligne, plus grande\n",
    "    fig, axes = plt.subplots(nrows=len(noise_levels)+1, ncols=2, figsize=(10, 3*(len(noise_levels)+1)))\n",
    "    fig.suptitle(f\"Reconstruction par patch - {fname}\", fontsize=18, y=1.01)\n",
    "\n",
    "    # Ligne 0 : clean\n",
    "    axes[0, 0].imshow(clean_img)\n",
    "    axes[0, 0].set_title(\"Clean\", fontsize=14)\n",
    "    axes[0, 0].axis('off')\n",
    "    axes[0, 1].axis('off')\n",
    "\n",
    "    # Boucle sur les niveaux de bruit\n",
    "    for j, noise_level in enumerate(noise_levels):\n",
    "        # Ajouter du bruit salt & pepper\n",
    "        noisy_img = add_salt_pepper_noise(clean_img, noise_level)\n",
    "        # Reconstruction par patch\n",
    "        patches, positions = extract_patches_and_positions(noisy_img, patch_size=32, stride=2)\n",
    "        # Normalisation des patches\n",
    "        denoised_patches = model.predict(patches, verbose=0)\n",
    "        # Reconstruction de l'image à partir des patches\n",
    "        recon_img = reconstruct_from_patches(denoised_patches, positions, clean_img.shape, patch_size=32)\n",
    "        recon_img = np.clip(recon_img, 0, 1)\n",
    "        # Calcul des métriques\n",
    "        psnr_val = psnr(clean_img, recon_img, data_range=1.0)\n",
    "        ssim_val = ssim(clean_img, recon_img, channel_axis=-1, data_range=1.0)\n",
    "        metrics[noise_level]['psnr'].append(psnr_val)\n",
    "        metrics[noise_level]['ssim'].append(ssim_val)\n",
    "\n",
    "        # Colonne 0 : bruitée\n",
    "        axes[j+1, 0].imshow(noisy_img)\n",
    "        axes[j+1, 0].set_title(f\"Noise {noise_level}\", fontsize=13)\n",
    "        axes[j+1, 0].axis('off')\n",
    "        # Colonne 1 : débruitée\n",
    "        axes[j+1, 1].imshow(recon_img)\n",
    "        axes[j+1, 1].set_title(f\"Denoised\\nPSNR={psnr_val:.2f} SSIM={ssim_val:.3f}\", fontsize=13)\n",
    "        axes[j+1, 1].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Moyennes globales\n",
    "avg_metrics = {level: {'psnr': np.mean(values['psnr']), 'ssim': np.mean(values['ssim'])} for level, values in metrics.items()}\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(noise_levels, [avg_metrics[level]['psnr'] for level in noise_levels], 'o-')\n",
    "plt.title('Average PSNR vs Salt & Pepper Noise Level')\n",
    "plt.xlabel('Noise Level')\n",
    "plt.ylabel('PSNR (dB)')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(noise_levels, [avg_metrics[level]['ssim'] for level in noise_levels], 'o-')\n",
    "plt.title('Average SSIM vs Salt & Pepper Noise Level')\n",
    "plt.xlabel('Noise Level')\n",
    "plt.ylabel('SSIM')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c392bc7",
   "metadata": {},
   "source": [
    "## 13. Denoising sur une Image Personnalisée\n",
    "\n",
    "Dans cette section, nous testons le modèle sur une image personnalisée. L'objectif est de débruiter une image bruitée et de visualiser les résultats, y compris les patchs débruités et l'image reconstruite.\n",
    "\n",
    "### Étapes :\n",
    "1. Charger une image bruitée personnalisée.\n",
    "2. Découper l'image en patches de taille fixe.\n",
    "3. Débruiter les patches avec le modèle.\n",
    "4. Afficher quelques patchs débruités pour visualiser les résultats intermédiaires.\n",
    "5. Reconstruire l'image complète à partir des patches débruités.\n",
    "6. Comparer visuellement l'image bruitée et l'image débruitée reconstruite.\n",
    "\n",
    "### Résultat attendu :\n",
    "- Une comparaison visuelle entre l'image bruitée (entrée) et l'image débruitée (sortie).\n",
    "- Une visualisation des patchs débruités pour mieux comprendre le fonctionnement du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd5e6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Fonction pour débruiter une image et visualiser les patchs\n",
    "def denoise_and_visualize_image(model, image_path, patch_size=32, stride=32, n_show=6):\n",
    "    \"\"\"\n",
    "    Débruite une image (déjà bruitée), affiche quelques patchs débruités et la reconstruction finale.\n",
    "    Args:\n",
    "        model: modèle keras entraîné pour le débruitage\n",
    "        image_path: chemin de l'image bruitée à traiter\n",
    "        patch_size: taille des patchs (par défaut 32)\n",
    "        stride: stride pour le découpage (par défaut 32)\n",
    "        n_show: nombre de patchs à afficher\n",
    "    \"\"\"\n",
    "\n",
    "    # Chargement de l'image bruitée\n",
    "    noisy_img = cv2.imread(image_path)\n",
    "    noisy_img = cv2.cvtColor(noisy_img, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0\n",
    "\n",
    "    # Découpage en patchs\n",
    "    h, w, c = noisy_img.shape\n",
    "    patches = []\n",
    "    positions = []\n",
    "    for y in range(0, h - patch_size + 1, stride):\n",
    "        for x in range(0, w - patch_size + 1, stride):\n",
    "            patch = noisy_img[y:y+patch_size, x:x+patch_size, :]\n",
    "            patches.append(patch)\n",
    "            positions.append((y, x))\n",
    "    patches = np.array(patches)\n",
    "\n",
    "    # Prédiction patch par patch\n",
    "    denoised_patches = model.predict(patches, verbose=0)\n",
    "\n",
    "    # Affichage de quelques patchs débruités\n",
    "    n_show = min(n_show, len(patches))\n",
    "    plt.figure(figsize=(12, 3))\n",
    "    for i in range(n_show):\n",
    "        plt.subplot(1, n_show, i+1)\n",
    "        plt.imshow(np.clip(denoised_patches[i], 0, 1))\n",
    "        plt.title(f\"Denoised patch {i+1}\")\n",
    "        plt.axis('off')\n",
    "    plt.suptitle(\"Exemples de patchs débruités\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Reconstruction de l'image débruitée\n",
    "    recon = np.zeros_like(noisy_img, dtype=np.float32)\n",
    "    weight = np.zeros_like(noisy_img, dtype=np.float32)\n",
    "    for patch, (y, x) in zip(denoised_patches, positions):\n",
    "        recon[y:y+patch_size, x:x+patch_size] += patch\n",
    "        weight[y:y+patch_size, x:x+patch_size] += 1\n",
    "    recon_img = recon / np.maximum(weight, 1e-8)\n",
    "    recon_img = np.clip(recon_img, 0, 1)\n",
    "\n",
    "    # Affichage final\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(noisy_img)\n",
    "    plt.title(\"Image bruitée (entrée)\")\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(recon_img)\n",
    "    plt.title(\"Image débruitée (sortie)\")\n",
    "    plt.axis('off')\n",
    "    plt.suptitle(\"Comparaison Noisy / Denoised\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Exemple d'utilisation\n",
    "image_path = \"Data Science/Datasets/Dataset Livrable 2 - patches/test/IMG20250415164601.jpg\"  # <-- Remplace par ton image\n",
    "denoise_and_visualize_image(model, image_path, patch_size=32, stride=16, n_show=6)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
